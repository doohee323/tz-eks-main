filebeat.inputs:
- type: log
  enabled: true
  paths:
    - /data/csv/*.csv

filebeat.config.modules:
  path: /etc/filebeat/modules.d/*.yml
  reload.enabled: false

setup.template:
  enabled: false
  settings:
    index.number_of_shards: 1

setup.kibana:
  host: "localhost:5601"

output.elasticsearch:
  protocol: https
  ssl.verification_mode: none
  hosts: ["elasticsearch-master.es.svc.cluster.local:9200"]
  username: 'elastic'
  password: 'Dlwpdldps!323'
#  index: "aws_usage-%{+yyyy.MM.dd}"
#  setup.template.name: "aws_usage-2"
#  setup.template.pattern: "aws_usage-*"
  pipeline: aws_usage

#output.logstash:
#  protocol: http
#  hosts: ["logstash-logstash.es.svc.cluster.local:5044"]

#processors:
#  - add_host_metadata:
#      when.not.contains.tags: forwarded
#  - add_cloud_metadata: ~
#  - add_docker_metadata: ~
#  - add_kubernetes_metadata: ~

processors:
  - decode_csv_fields:
      fields:
        message: decoded.csv
      separator: ","
      ignore_missing: false
      overwrite_keys: true
      trim_leading_space: false
      fail_on_error: true

logging.level: debug
monitoring.enabled: false

setup.ilm.enabled: false

